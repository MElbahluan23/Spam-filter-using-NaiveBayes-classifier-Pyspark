{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9da32d6",
   "metadata": {},
   "source": [
    "# NLP Using PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326ba88",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "- The objective from this project is to create a <b>Spam filter using NaiveBayes classifier</b>.\n",
    "- We'll use a dataset from UCI Repository. SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc851",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Create a spark session and import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf86e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SpamFilter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00718f",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Read the data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29914cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "|spam|FreeMsg Hey there...|\n",
      "| ham|Even my brother i...|\n",
      "| ham|As per your reque...|\n",
      "|spam|WINNER!! As a val...|\n",
      "|spam|Had your mobile 1...|\n",
      "| ham|I'm gonna be home...|\n",
      "|spam|SIX chances to wi...|\n",
      "|spam|URGENT! You have ...|\n",
      "| ham|I've been searchi...|\n",
      "| ham|I HAVE A DATE ON ...|\n",
      "|spam|XXXMobileMovieClu...|\n",
      "| ham|Oh k...i'm watchi...|\n",
      "| ham|Eh u remember how...|\n",
      "| ham|Fine if thats th...|\n",
      "|spam|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"dataset/SMSSpamCollection\",inferSchema=True,sep='\\t')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182cd7f6",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52706b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90cce7",
   "metadata": {
    "id": "gUxZnsqrmynW"
   },
   "source": [
    "### Rename the first column to 'class' and second column to 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a88df6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e798d0",
   "metadata": {},
   "source": [
    "### Show the first 10 rows from the dataframe\n",
    "- Show once with truncate=True and once with truncate=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362dcb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "|  ham|U dun say so earl...|\n",
      "|  ham|Nah I don't think...|\n",
      "| spam|FreeMsg Hey there...|\n",
      "|  ham|Even my brother i...|\n",
      "|  ham|As per your reque...|\n",
      "| spam|WINNER!! As a val...|\n",
      "| spam|Had your mobile 1...|\n",
      "+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41609e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|class|text                                                                                                                                                            |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                 |\n",
      "|ham  |Ok lar... Joking wif u oni...                                                                                                                                   |\n",
      "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's     |\n",
      "|ham  |U dun say so early hor... U c already then say...                                                                                                               |\n",
      "|ham  |Nah I don't think he goes to usf, he lives around here though                                                                                                   |\n",
      "|spam |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv             |\n",
      "|ham  |Even my brother is not like to speak with me. They treat me like aids patent.                                                                                   |\n",
      "|ham  |As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune|\n",
      "|spam |WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.   |\n",
      "|spam |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030      |\n",
      "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe744a9",
   "metadata": {},
   "source": [
    "## Clean and Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d693167",
   "metadata": {},
   "source": [
    "### Create a new feature column contains the length of the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5424a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f083156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('length',length(df['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea2de6",
   "metadata": {},
   "source": [
    "### Show the new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c67c53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "| spam|FreeMsg Hey there...|   147|\n",
      "|  ham|Even my brother i...|    77|\n",
      "|  ham|As per your reque...|   160|\n",
      "| spam|WINNER!! As a val...|   157|\n",
      "| spam|Had your mobile 1...|   154|\n",
      "|  ham|I'm gonna be home...|   109|\n",
      "| spam|SIX chances to wi...|   136|\n",
      "| spam|URGENT! You have ...|   155|\n",
      "|  ham|I've been searchi...|   196|\n",
      "|  ham|I HAVE A DATE ON ...|    35|\n",
      "| spam|XXXMobileMovieClu...|   149|\n",
      "|  ham|Oh k...i'm watchi...|    26|\n",
      "|  ham|Eh u remember how...|    81|\n",
      "|  ham|Fine if thats th...|    56|\n",
      "| spam|England v Macedon...|   155|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e37a6",
   "metadata": {},
   "source": [
    "### Get the average text length for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c32727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|   Average Length|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "df.groupby('class').agg(mean('length').alias(\"Average Length\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e101af",
   "metadata": {},
   "source": [
    "## Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4eebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82756db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
    "stopwordsRemover = StopWordsRemover(inputCol='tokens',outputCol='stopTokens')\n",
    "countVec = CountVectorizer(inputCol='stopTokens',outputCol='countVec')\n",
    "tf_idf = IDF(inputCol=\"countVec\", outputCol=\"tf_idf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf46159",
   "metadata": {},
   "outputs": [],
   "source": [
    "textToNum = StringIndexer(inputCol='class',outputCol='label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad9d4c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuers = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9775d494",
   "metadata": {},
   "source": [
    "## The Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57af0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c7384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naiveBayes = NaiveBayes(featuresCol='features',labelCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14de63",
   "metadata": {},
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee0d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipline = Pipeline(stages=[textToNum,tokenizer,stopwordsRemover,countVec,tf_idf,featuers])\n",
    "pipline_FIT = pipline.fit(df)\n",
    "pipline_TF = pipline_FIT.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f82bab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|class|                text|length|label|              tokens|          stopTokens|            countVec|              tf_idf|            features|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  ham|Go until jurong p...|   111|  0.0|[go, until, juron...|[go, jurong, poin...|(13423,[7,11,31,6...|(13423,[7,11,31,6...|(13424,[7,11,31,6...|\n",
      "|  ham|Ok lar... Joking ...|    29|  0.0|[ok, lar..., joki...|[ok, lar..., joki...|(13423,[0,24,297,...|(13423,[0,24,297,...|(13424,[0,24,297,...|\n",
      "| spam|Free entry in 2 a...|   155|  1.0|[free, entry, in,...|[free, entry, 2, ...|(13423,[2,13,19,3...|(13423,[2,13,19,3...|(13424,[2,13,19,3...|\n",
      "|  ham|U dun say so earl...|    49|  0.0|[u, dun, say, so,...|[u, dun, say, ear...|(13423,[0,70,80,1...|(13423,[0,70,80,1...|(13424,[0,70,80,1...|\n",
      "|  ham|Nah I don't think...|    61|  0.0|[nah, i, don't, t...|[nah, think, goes...|(13423,[36,134,31...|(13423,[36,134,31...|(13424,[36,134,31...|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pipline_TF\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7efbe",
   "metadata": {},
   "source": [
    "### Split the data to trian and test data with ratios 0.7 and 0.3 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2843d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "training,testing = data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17ff4fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- stopTokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- countVec: vector (nullable = true)\n",
      " |-- tf_idf: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcea576",
   "metadata": {},
   "source": [
    "### Fit the Pipeline model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c5d4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = naiveBayes.fit(training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a3eb1",
   "metadata": {},
   "source": [
    "### Perform predictions on tests dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14f4aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2885f",
   "metadata": {},
   "source": [
    "### Print the schema of the prediction dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e3ea341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- class: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- length: integer (nullable = true)\n",
      " |-- label: double (nullable = false)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- stopTokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- countVec: vector (nullable = true)\n",
      " |-- tf_idf: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f27055",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61911086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "acc_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "f1Score = acc_f1.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af1f9ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score is: 0.918181792392265\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score is: {}\".format(f1Score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
